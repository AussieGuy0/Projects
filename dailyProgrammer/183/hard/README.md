# Dimensionality Reduction
<div class="md"><h1><a href="#HardIcon"></a> <em>(Hard)</em>: Dimensionality Reduction</h1>
<p>I have submitted in such a long time so i though i give a hard challenge! This week's and next week's hard challenge will be a machine learning/data mining challenge which are in quite high demand and have applications in today's top companies like facebook, google, quora, twitter and hundreds of multiple other companies. It will be a long challenge so do note that there will be another hard challenge next week which will be the continuation to this one.</p>
<p>This challenge consists of three parts and we will be doing two parts this week.</p>
<h2>Problem Description</h2>
<p><strong>Part 1:</strong></p>
<p><strong>Do read the note below part 1 before proceeding.</strong></p>
<ul>
<li><p>Create a sparse matrix with a large number of dimension like 1000 rows and 120,000 columns with different values in it.</p></li>
<li><p>Since some people might have memory problems its alright if you reduce the number of columns to say 12000 or 1200 or even lesser if you feel necessary. That would be fine too for learning purposes.</p></li>
<li><p>Create a list of labels for the corresponding sparse matrix with the same number of rows and have a fixed number for the type of labels such as 20 or 25. Again i give you the freedom to reduce the number of labels if necessary. The point of the challenge is to learn the idea of dimensionality reduction.</p></li>
<li><p>Create a testing set which is a smaller sparse matrix with corresponding labels</p></li>
</ul>
<hr/>
<p><strong>Note:</strong> In case you want to play with real data do make it a point to visit these pages</p>
<ul>
<li><p><a href="http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public">http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public</a></p></li>
<li><p><a href="http://stackoverflow.com/questions/381806/large-public-datasets">http://stackoverflow.com/questions/381806/large-public-datasets</a></p></li>
</ul>
<p>For public available datasets over which you can do part 2. You can skip part 1 if you use the public datasets ;)</p>
<hr/>
<p><strong>Part 2:</strong> </p>
<p>Input: </p>
<ol>
<li><p>Training input which is a Random Sparse matrix of large number of rows and columns say 1000 x 120000 matrix from the <strong>part 1</strong>.</p></li>
<li><p>Classification label for each row in the training input <strong>part 1</strong>.</p></li>
</ol>
<ul>
<li>Perform dimensionality reduction using algorithms like Principal Component Analysis</li>
</ul>
<p>Do note you can use any language necessary. I would suggest matlab to be honest since it will make your work easier ;)</p>
<h2>Some helpful Links</h2>
<ul>
<li><p>what is a sparse matrix ?<br/>
<a href="http://en.wikipedia.org/wiki/Sparse_matrix">http://en.wikipedia.org/wiki/Sparse_matrix</a></p></li>
<li><p>what is supervised learning ?<br/>
<a href="http://en.wikipedia.org/wiki/Supervised_learning">http://en.wikipedia.org/wiki/Supervised_learning</a></p></li>
<li><p>What is dimensionality reduction ?<br/>
<a href="http://en.wikipedia.org/wiki/Dimensionality_reduction">http://en.wikipedia.org/wiki/Dimensionality_reduction</a></p></li>
<li><p>Some info on testing set, training set..<br/>
<a href="http://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set">http://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set</a></p></li>
<li><p>What is k-fold cross validation ?<br/>
<a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation">http://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation</a></p></li>
</ul>
<hr/>
<p>Feel free to talk about the challenge in the IRC</p>
<p><a href="http://webchat.freenode.net/">http://webchat.freenode.net/</a> </p>
<ul>
<li>channel: #reddit-dailyprogrammer</li>
</ul>
</div>
